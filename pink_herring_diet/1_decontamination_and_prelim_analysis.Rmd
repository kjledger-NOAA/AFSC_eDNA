---
title: "Decontamination and preliminary analysis of ASVs and samples from the pink salmon and herring stomach MiFish metabarcoding"
author: "Kimberly Ledger"
date: "2023-11-21"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Inputs: This code starts with the ASV table output from dada_blast.sh that uses dadasnake for preliminary quality control. We also use sample metadata and taxonomic id generated from insect classifier for MiFish and blast for the ASVs in this code.  

Outputs: We will end up with a decontaminated taxonomy table that can be used for additional analyses.  

Decontamination will involve **these steps**:  

**1. Estimate tag-jumping** - There is the potential for barcodes (that are used to identify the individual samples in a MiSeq run) to be assigned to the wrong sample for a variety of reasons. While we can't tell exactly which mechanism generated these errors, we can still estimate the occurrence of tag-jumping and account for it in our dataset. To do this, we will consider our positive control samples (which have known composition and are extremely unlikely to be present in the environmental samples) as representatives of the amount of tag-jumping occurring across the entire dataset. Specifically, what we will do is subtract the proportion of reads observed in the control samples from each environmental sample. The output will be a dataset with the same number of samples and ASVs as before, but with fewer reads of certain sequences (ASVs). We expect this bias in tag-jumping to be frequency-dependent (i.e. the more abundant ASVs are more likely to be found in samples where they are not suppose to be.)

**2. Account for contaminants in positive and negative controls** - We can use the reads that show up where we know they shouldn't be (i.e. the controls) to further clean up the dataset. We will remove ASVs that only occur in controls and not in environmental samples. And then we will subtract the maximum number of reads from ASVs found in either the extraction or pcr controls from all samples. The output will be a dataset with the same number of samples as before but with fewer ASVs.  

**3. Discard PCR replicates with low numbers of reads** - Sometimes PCR replicates have low read numbers, and therefore will have skewed relative read proportions. These should be removed.  To do this we will discard samples with <1000 reads. The output will be a dataset with fewer samples and potentially fewer ASVs.  

**4. Remove ASVs with low numbers of reads** 

## Load libraries and data 

load libraries 
```{r, message=FALSE}
library(tidyverse)
library(dplyr)
```

load ASV table and metadata
```{r}
asv_table <- readRDS("/home/kimberly.ledger/AFSC_eDNA/pink_herring_diet/filtered.seqTab.RDS") %>%
  select(!Row.names)

#transpose 
asv_table <- data.frame(t(asv_table))

#set column names to be ASV# 
colnames(asv_table) <- asv_table["ASV",]

#remove row 
asv_table <- asv_table[-144,]

#make sure reads are numbers
# Convert all character columns to numeric
for (col in names(asv_table)) {
  asv_table[[col]] <- as.numeric(asv_table[[col]])
}

#make make sample ID a column 
asv_table$Sample_ID <- rownames(asv_table)
asv_table$Sample_ID <- as.factor(asv_table$Sample_ID)

metadata <- read.csv("/home/kimberly.ledger/AFSC_eDNA/pink_herring_diet/pinkherring_diet_metadata.csv") %>%
  dplyr::rename(Sample_ID = extraction_ID)

#illumina output changed "_" to "-"
metadata$Sample_ID <- gsub("_", "-", metadata$Sample_ID) 
```

let's start by taking a closer looks at our dataset 
```{r}
## number of ASVs 
sum(grepl("ASV", colnames(asv_table)))  

## number of samples in ASV table 
nrow(asv_table)
```

note: sample name "PC-29" is actually the negative control from plate 28 

before diving into the decontamination steps, let's get a feel for what the data look like. 

### positive controls 

add column to the ASV table that labels the sample type
```{r}
asv_table_with_sample_type <- metadata %>%
  dplyr::select(Sample_ID, sample_type) %>%
  left_join(asv_table, by = "Sample_ID")
```


let's start by visualizing the reads in the positive control samples 
```{r}
asv_table_with_sample_type %>%
  pivot_longer(cols = c(3:413), names_to = "ASV", values_to = "reads") %>%
  filter(sample_type == "positive") %>%
  ggplot(aes(x=Sample_ID, y=reads, fill=ASV)) +
  geom_bar(stat = "identity") + 
    theme_bw() +
  labs(
    y = "number of sequencing reads",
    x = "sample ID",
    title = "ASV reads in positive controls") + 
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.text = element_text(size = 8),
    legend.key.size = unit(0.3, "cm"),
    legend.position = "none",
    legend.title = element_blank()
  )
```

top asvs in positive controls
```{r}
asvs_PC <- asv_table_with_sample_type %>%
  pivot_longer(cols = c(3:413), names_to = "ASV", values_to = "reads") %>%
  filter(sample_type == "positive") %>%
  group_by(ASV) %>%
  summarise(total = sum(reads)) %>%
  arrange(desc(total))

head(asvs_PC, 6)
```


### extraction blanks 

let me look into the reads that got into the extraction blanks
```{r}
asv_table_with_sample_type %>%
  pivot_longer(cols = c(3:413), names_to = "ASV", values_to = "reads") %>%
  filter(sample_type == "extraction_blank") %>%
  ggplot(aes(x=Sample_ID, y=reads, fill=ASV)) +
  geom_bar(stat = "identity") + 
    theme_bw() +
  labs(
    y = "number of sequencing reads",
    x = "sample ID",
    title = "ASV reads - extraction blanks") + 
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.text = element_text(size = 8),
    legend.key.size = unit(0.3, "cm"),
    legend.position = "none",
    legend.title = element_blank()
  )
```


```{r}
asvs_EC <- asv_table_with_sample_type %>%
  pivot_longer(cols = c(3:413), names_to = "ASV", values_to = "reads") %>%
  filter(sample_type == "extraction_blank") %>%
  group_by(ASV) %>%
  summarise(total = sum(reads)) %>%
  arrange(desc(total))

head(asvs_EC, 10)
```

### pcr blanks 

let me look into the reads that got into the pcr blanks
```{r}
asv_table_with_sample_type %>%
  pivot_longer(cols = c(3:413), names_to = "ASV", values_to = "reads") %>%
  filter(sample_type == "pcr_blank") %>%
  ggplot(aes(x=Sample_ID, y=reads, fill=ASV)) +
  geom_bar(stat = "identity") + 
    theme_bw() +
  labs(
    y = "number of sequencing reads",
    x = "sample ID",
    title = "ASV reads - pcr negatives") + 
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.text = element_text(size = 8),
    legend.key.size = unit(0.3, "cm"),
    legend.position = "none",
    legend.title = element_blank()
  )
```

```{r}
asvs_PCRN <- asv_table_with_sample_type %>%
  pivot_longer(cols = c(3:413), names_to = "ASV", values_to = "reads") %>%
  filter(sample_type == "pcr_blank") %>%
  group_by(ASV) %>%
  summarise(total = sum(reads)) %>%
  arrange(desc(total))

head(asvs_PCRN, 10)
```


## 1. Estimate index hopping  
subtract the proportion of reads that jumped into the positive control samples from each environmental sample 

identify the maximum proportion of reads for each ASV found in the positive controls
```{r}
prop_asvs_in_positives <- asv_table_with_sample_type %>%
  #filter(sample_type == "positive") %>%
  filter(Sample_ID == "PC-28") %>%
  pivot_longer(cols = c(3:413), names_to = "ASV", values_to = "reads") %>%
  group_by(Sample_ID) %>%
  mutate(TotalReadsPerSample = sum(reads)) %>%
  mutate(Prop = reads/TotalReadsPerSample) %>%
  group_by(ASV) %>%
  summarise(max_prop = max(Prop))
```

subtract the max proportion of tag-jumped reads for each ASV from all samples
```{r}
indexhop_table <- asv_table_with_sample_type %>%
  pivot_longer(cols = c(3:413), names_to = "ASV", values_to = "reads") %>%
  group_by(Sample_ID) %>%
  mutate(TotalReadsPerSample = sum(reads)) %>%
  left_join(prop_asvs_in_positives, by = "ASV") %>%
  mutate(IndexHoppingReads = TotalReadsPerSample*max_prop) %>%
  mutate(reads_IndexHop_removed = reads - IndexHoppingReads) %>%
  mutate(reads_IndexHop_removed = if_else(reads_IndexHop_removed < 0, 0, reads_IndexHop_removed))
head(indexhop_table)
```


note: only basing tag jumping estimates on one of the positive controls 

clean up the table by removing columns no longer needed 
```{r}
asv_table_filter1 <- indexhop_table %>%
  dplyr::select(Sample_ID, sample_type, ASV, reads_IndexHop_removed) %>%
  dplyr::rename(reads = reads_IndexHop_removed)
```

this is a summary of the number of reads removed by ASV and sample_ID
```{r}
decontaminated_1 <- indexhop_table %>%
  dplyr::select(Sample_ID, ASV, IndexHoppingReads) %>%
  pivot_wider(names_from = "ASV", values_from = "IndexHoppingReads")
head(decontaminated_1)
```

and a list of the proportion of reads from ASVs removed 
```{r}
prop_removed_1 <- prop_asvs_in_positives %>%
  arrange(desc(max_prop))
head(prop_removed_1)
```


## 2. Account for contaminants in positive and negative controls 

next we will remove ASVs that only occur in controls and not in environmental samples. 

let's start by taking a look at what reads remain in these controls 
```{r}
asv_table_filter1 %>%
  filter(sample_type != "sample") %>%
  ggplot(aes(x=Sample_ID, y=reads, fill=ASV)) +
  geom_bar(stat = "identity") + 
    theme_bw() +
  labs(
    y = "number of sequencing reads",
    x = "sample ID",
    title = "ASV reads - controls") + 
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.text = element_text(size = 8),
    legend.key.size = unit(0.3, "cm"),
    legend.position = "none",
    legend.title = element_blank()
  )
```

number of reads
```{r}
tempA <- asv_table_filter1 %>%
  group_by(ASV, sample_type) %>%
  summarize(TotalReadsPerASV = sum(reads)) %>%
  arrange(ASV)
```

what ASVs have no reads in samples, but reads in the controls? 
```{r}
tempB <- tempA %>%
  pivot_wider(names_from = "sample_type", values_from = c("TotalReadsPerASV")) %>%
    filter(sample < 1)
head(tempB)
```

remove these from the data frame 
```{r}
asv_table_filter1.5 <- asv_table_filter1 %>%
  filter(!ASV %in% tempB$ASV)
```


how much does this change things?
```{r}
asv_table_filter1.5 %>%
  filter(sample_type != "sample") %>%
  ggplot(aes(x=Sample_ID, y=reads, fill=ASV)) +
  geom_bar(stat = "identity") + 
    theme_bw() +
  labs(
    y = "number of sequencing reads",
    x = "sample ID",
    title = "ASV reads - controls") + 
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.text = element_text(size = 8),
    legend.key.size = unit(0.3, "cm"),
    legend.position = "none",
    legend.title = element_blank()
  )
```

next we will subtract the maximum number of reads from ASVs found in the extraction and pcr negative controls from all samples.

calculate the maximum number of reads in an ASV to still show up in an extraction or PCR negative control 
```{r}
reads_to_remove_per_ASV <- asv_table_filter1.5 %>%
  filter(sample_type == "extraction_blank"| sample_type == "pcr_blank") %>%
  group_by(ASV) %>%
  summarize(max_reads = max(reads))

reads_to_remove_per_sample <- asv_table_filter1.5 %>%
  left_join(reads_to_remove_per_ASV, by = "ASV") %>%
  mutate(read_minus_contamination = reads - max_reads) %>%
  mutate(read_minus_contamination = if_else(read_minus_contamination < 0, 0, read_minus_contamination))
```

filter the data frame 
```{r}
asv_table_filter2 <- reads_to_remove_per_sample %>%
  dplyr::select(!reads) %>%
  dplyr::select(!max_reads) %>%
  dplyr::rename(reads = read_minus_contamination)
```

number of ASVs remaining
```{r}
length(unique(asv_table_filter2$ASV)) 
```

this step does remove a lot of reads from some of the ASVs but i think this is okay since read numbers are quite high and we should see a clear picture of species presence despite removing these reads 


## 3. Discard PCR replicates with low numbers of reads 

calculate reads per sample
```{r}
all_reads <- asv_table_filter2 %>%
  group_by(Sample_ID) %>%
  summarize(ReadsPerSample = sum(reads))
```

visualize 
```{r}
all_reads$x_reordered <- reorder(all_reads$Sample_ID, -all_reads$ReadsPerSample)

all_reads %>%
  ggplot(aes(x = x_reordered, y = ReadsPerSample)) + 
  geom_bar(stat = "identity")
```

fit a normal distribution
```{r}
fit <- MASS::fitdistr(all_reads$ReadsPerSample, "normal")

all_reads %>%  
  mutate(prob = pnorm(all_reads$ReadsPerSample, fit$estimate[[1]], fit$estimate[[2]])) -> all_reads
```

identify and remove the outliers
```{r}
#low_dist_probability_cutoff <- 0.05
minimum_read_cutoff <- 1000

outliers <- all_reads %>% 
  #filter(prob < low_dist_probability_cutoff | ReadsPerSample < minimum_read_cutoff)
  filter(ReadsPerSample < minimum_read_cutoff)

outlierIDs <- outliers$Sample_ID
```

which samples are removed because of the 1000 reads threshold??
```{r}
replicates_removed <- asv_table_filter2 %>%
  filter(Sample_ID %in% outlierIDs) %>%
  pivot_wider(names_from = "ASV", values_from = "reads")
#head(replicates_removed_2)
```

number of pcr replicates removed
```{r}
nrow(replicates_removed)
```

plot them
```{r}
replicates_removed %>%
  pivot_longer(cols = c(3:402), names_to = "ASV", values_to = "count") %>%
ggplot(aes(x=Sample_ID, y=count, fill=ASV)) +
  geom_bar(stat = "identity") + 
    theme_bw() + 
   labs(
    y = "sequencing reads",
    x = "sample ID",
    title = "samples with low read numbers")  +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.position = "none",
    legend.title = element_blank()
  )  
```

filter the data frame 
```{r}
asv_table_filter3 <- asv_table_filter2 %>%
  filter(!Sample_ID %in% outlierIDs)
```



## 4. Remove ASVs with low numbers of reads 

what ASV's have more than 1000 reads in the dataset? 
```{r}
asv_keepers <- asv_table_filter3 %>%
  group_by(ASV) %>%
  summarize(total = sum(reads)) %>%
  arrange(desc(total)) %>%
  filter(total > 1000)
```

```{r}
asv_table_filter4 <- asv_table_filter3 %>%
  filter(ASV %in% asv_keepers$ASV)
```


## 5. Join to taxonomy and get rid of ASVs with no ID 

because the insect and the blastn classifiers aren't perfect on their own, i combined the outputs by hand for our remaining ASVs
```{r}
my_tax <- read.csv("asv_taxonomy_pinkherringdiet_custom.csv")
```


late addition:  let's seperare the salmon ASVs to see how they track... 
```{r}
my_tax <- my_tax %>%
  mutate(taxon = ifelse(representative == "ASV2", "Oncorhynchus_2", taxon)) %>%
  mutate(taxon = ifelse(representative == "ASV4", "Oncorhynchus_4", taxon)) %>%
  mutate(taxon = ifelse(representative == "ASV9", "Oncorhynchus_9", taxon)) %>%
  mutate(taxon = ifelse(representative == "ASV50", "Oncorhynchus_50", taxon))
```


join to taxononmy and group reads by taxon assigment
```{r}
taxon_table <- asv_table_filter4 %>%
  separate(ASV, into = c("ASV_label", "ASV_num"), remove = F) %>%
  mutate(ASV_num = as.integer(ASV_num)) %>%
  left_join(my_tax, by = "ASV_num") %>%
  select(!ASV_label) %>%
  select(!ASV_num) %>% 
  select(!representative) %>%
  group_by(Sample_ID, taxon, rank, order, family, genus, species) %>%
  summarize(reads = sum(reads)) %>%
  filter(!is.na(taxon))
```

join the sample metadata so that we know which species of fish the sample came from

we had incorrect metadata for 23-5-217. reclassify to Pacific herring
```{r}
metadata <- metadata %>%
  mutate(Species = ifelse(Sample_ID == "e02950", "Pacific herring", Species))
```

```{r}
taxon_table_w_meta <- taxon_table %>%
  left_join(metadata, by = "Sample_ID") %>%
  filter(sample_type != "positive")
```



# Pacific herring 

## let's look at what taxa are the in Pacific herring stomach samples 
```{r}
herring_stomachs <- taxon_table_w_meta %>% 
  filter(Species == "Pacific herring")

herring_stomachs %>%
  group_by(taxon) %>%
  summarise(total = sum(reads)) %>%
  arrange(desc(total))
```

total number of reads in herring stomachs
```{r}
sum(herring_stomachs$reads)
```
number and proportion of non-herring reads
```{r}
sum(herring_stomachs$reads) - 1518201
(sum(herring_stomachs$reads) - 1518201) / sum(herring_stomachs$reads)
```

how many samples? how many stomachs? 
```{r}
length(unique(herring_stomachs$Sample_ID))
length(unique(herring_stomachs$FishID))

```

which stomachs had multiple extractions? 
```{r}
replicates <- metadata %>%
  group_by(Species, FishID) %>%
  summarise(n_extractions = n()) %>%
  filter(n_extractions > 1)
replicates
```

plot reads WITH herring 
```{r}
herring_stomachs %>%
  #filter(family != "Clupeidae") %>%
ggplot(aes(x=Sample_ID, y=reads, fill=taxon)) +
  geom_bar(stat = "identity") + 
    theme_bw() + 
   labs(
    y = "sequencing reads",
    x = "sample ID",
    title = "herring stomachs with herring reads")  +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.position = "none",
    legend.title = element_blank()
  )  
```

plot reads WITHOUT herring 
```{r}
herring_stomachs %>%
  filter(family != "Clupeidae") %>%
ggplot(aes(x=Sample_ID, y=reads, fill=taxon)) +
  geom_bar(stat = "identity") + 
    theme_bw() + 
   labs(
    y = "sequencing reads",
    x = "sample ID",
    title = "herring stomachs without herring reads")  +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.position = "none",
    legend.title = element_blank()
  )  
```


let's say a sample need >1000 non-herring reads in order to establish its diet 
```{r}
herring_diet <- herring_stomachs %>%
  filter(family != "Clupeidae") %>%
  group_by(Sample_ID) %>%
  mutate(ReadsPerSample = sum(reads)) %>%
  filter(ReadsPerSample > 1000) %>%
  mutate(read_prop = reads/ReadsPerSample)
```

how many samples? 
```{r}
length(unique(herring_diet$FishID))
length(unique(herring_diet$Sample_ID))
```

plot them - number of reads 
```{r}
herring_diet %>%
ggplot(aes(x=Sample_ID, y=reads, fill=taxon)) +
  geom_bar(stat = "identity") + 
    theme_bw() + 
   labs(
    y = "number  of sequencing reads",
    x = "sample ID",
    title = "herring stomachs")  +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.position = "none",
    legend.title = element_blank()
  )  
```

plot them - proportion 
```{r, fig.height=6}
#order <- herring_diet %>%
#  filter(taxon == "Oncorhynchus") %>%
#  arrange(desc(read_prop))

#h_order <- order$Sample_ID

#herring_diet$Sample_ID <- factor(herring_diet$Sample_ID , levels = h_order)

herring_diet %>%
ggplot(aes(x=Sample_ID, y=read_prop, fill=taxon)) +
  geom_bar(stat = "identity") + 
    theme_bw() + 
   labs(
    y = "proportion of sequencing reads",
    x = "sample ID",
    title = "herring stomachs")  +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.position = "right",
    legend.text = element_text(size = 6),
    legend.title = element_blank()
  )  
```


total number of reads assigned to taxa in herring stomachs
```{r}
herring_diet %>%
  group_by(taxon) %>%
  summarize(total = sum(reads)) %>%
  arrange(desc(total))
```

average proportion of reads in herring stomachs (NA;s removed)
```{r}
herring_diet %>%
  group_by(taxon) %>%
  summarize(avg_prop = mean(read_prop, rm.na = T)) %>%
  arrange(desc(avg_prop))
```

a few stomachs had duplicate DNA extractions, let's check out those samples 
```{r}
herring_replicates <- herring_diet %>%
  filter(FishID %in% replicates$FishID)
```

```{r}
herring_replicates %>%
ggplot(aes(x=Sample_ID, y=read_prop, fill=taxon)) +
  geom_bar(stat = "identity") + 
    theme_bw() + 
   labs(
    y = "proportion of sequencing reads",
    x = "sample ID",
    title = "herring stomachs")  +
  facet_wrap(~FishID, scales = 'free') + 
  theme(
    axis.text.x = element_blank(),
    legend.position = "right",
    legend.text = element_text(size = 6),
    legend.title = element_blank()
  )  
```

okay, cool. the stomachs with replicate samples that both made it through the filtering do generally look similar.  

which herring stomachs have salmon reads? 
```{r}
samples_w_salmon <- herring_diet %>%
  filter(genus == "Oncorhynchus") %>%
  filter(reads > 0)

herring_diet %>%
  filter(Sample_ID %in% samples_w_salmon$Sample_ID) %>%
ggplot(aes(x=Sample_ID, y=read_prop, fill=taxon)) +
  geom_bar(stat = "identity") + 
    theme_bw() + 
   labs(
    y = "proportion of sequencing reads",
    x = "sample ID",
    title = "herring stomachs w Oncorhynchus reads")  +
  facet_wrap(~FishID, scales = 'free') + 
  theme(
    #axis.text.x = element_text(angle = 90, hjust = 0.95),
    axis.text.x = element_blank(),
    legend.position = "right",
    legend.text = element_text(size = 6),
    legend.title = element_blank()
  )  
```

2 stomachs do have large proportions (>90%) salmon reads.  read numbers aren't huge for these samples (2000-4000 reads). 


# Pink salmon 

## let's look at what species are the in pink salmon stomach samples 
```{r}
pink_stomachs <- taxon_table_w_meta %>% 
  filter(Species == "Pink salmon")

pink_stomachs %>%
  group_by(taxon) %>%
  summarise(total = sum(reads)) %>%
  arrange(desc(total))
```

total number of reads in pink salmon samples 
```{r}
sum(pink_stomachs$reads)
```

number and proportion of non-herring reads
```{r}
sum(pink_stomachs$reads) - 1471939
(sum(pink_stomachs$reads) - 1471939) / sum(pink_stomachs$reads)
```

how many samples? how many stomachs? 
```{r}
length(unique(pink_stomachs$Sample_ID))
length(unique(pink_stomachs$FishID))
```

```{r}
pink_stomachs %>%
ggplot(aes(x=Sample_ID, y=reads, fill=taxon)) +
  geom_bar(stat = "identity") + 
    theme_bw() + 
   labs(
    y = "sequencing reads",
    x = "sample ID",
    title = "pink salmon stomachs with salmon reads")  +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.position = "right",
    legend.title = element_blank(),
    legend.text = element_text(size = 6)
  )  
```

```{r}
pink_stomachs %>%
  filter(taxon != "Oncorhynchus") %>%
ggplot(aes(x=Sample_ID, y=reads, fill=taxon)) +
  geom_bar(stat = "identity") + 
    theme_bw() + 
   labs(
    y = "sequencing reads",
    x = "sample ID",
    title = "pink salmon stomach without salmon reads")  +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.position = "right",
    legend.title = element_blank(),
    legend.text = element_text(size = 6)
  )  
```


let's say a sample need >1000 non-herring reads in order to establish its diet 
```{r}
pink_diet <- pink_stomachs %>%
  filter(taxon != "Oncorhynchus") %>%
  group_by(Sample_ID) %>%
  mutate(ReadsPerSample = sum(reads)) %>%
  filter(ReadsPerSample > 1000) %>%
  mutate(read_prop = reads/ReadsPerSample)
```

how many samples? 
```{r}
length(unique(pink_diet$Sample_ID))
length(unique(pink_diet$FishID))
```

plot them - number of reads
```{r}
pink_diet %>%
ggplot(aes(x=Sample_ID, y=reads, fill=taxon)) +
  geom_bar(stat = "identity") + 
    theme_bw() + 
   labs(
    y = "number of sequencing reads",
    x = "sample ID",
    title = "pink salmon stomachs")  +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.position = "right",
    legend.title = element_blank(),
    legend.text = element_text(size = 6)
  )  
```

plot them - proportion of reads 
```{r, fig.height=6}
order <- pink_diet %>%
  filter(taxon == "Clupea pallasii") %>%
  arrange(desc(read_prop))

p_order <- order$Sample_ID

pink_diet$Sample_ID <- factor(pink_diet$Sample_ID , levels = p_order)

pink_diet %>%
ggplot(aes(x=Sample_ID, y=read_prop, fill=taxon)) +
  geom_bar(stat = "identity") + 
    theme_bw() + 
   labs(
    y = "proportion of sequencing reads",
    x = "sample ID",
    title = "pink salmon stomachs")  +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.position = "right",
    legend.title = element_blank(),
    legend.text = element_text(size = 8),
  )  
```


```{r}
pink_diet %>%
  group_by(taxon) %>%
  summarize(total = sum(reads)) %>%
  arrange(desc(total))
```

```{r}
pink_diet %>%
  group_by(taxon) %>%
  summarize(avg_prop = mean(read_prop, rm.na = T)) %>%
  arrange(desc(avg_prop))
```


which pink stomachs have herring reads? 
```{r}
samples_w_herring <- pink_diet %>%
  filter(taxon == "Clupea pallasii") %>%
  filter(reads > 0)

pink_diet %>%
  filter(Sample_ID %in% samples_w_herring$Sample_ID) %>%
ggplot(aes(x=Sample_ID, y=read_prop, fill=taxon)) +
  geom_bar(stat = "identity") + 
    theme_bw() + 
   labs(
    y = "proportion of sequencing reads",
    x = "sample ID",
    title = "pink stomachs w Clupea pallasii reads")  +
  #facet_wrap(~FishID, scales = 'free') + 
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    #axis.text.x = element_blank(),
    legend.position = "right",
    legend.text = element_text(size = 6),
    legend.title = element_blank()
  )  
```


## format results for output table 

start with metadata 
```{r}
meta_mini <- metadata %>%
  filter(sample_type == "sample") %>%
  select(Sample_ID:location) %>%
  mutate(extracted = "yes") %>%
  mutate(pass_QC = "NA")
```

pivot herring diet 
```{r}
herring_wide <- herring_diet %>%
  select(Sample_ID, FishID, ReadsPerSample, taxon, read_prop) %>%
  pivot_wider(names_from = taxon, values_from = read_prop)
```

pivot pink diet 
```{r}
pink_wide <- pink_diet %>%
  select(Sample_ID, FishID, ReadsPerSample, taxon, read_prop) %>%
  pivot_wider(names_from = taxon, values_from = read_prop)
```

join tables 
```{r}
join1 <- herring_wide %>%
  bind_rows(pink_wide)

join2 <- meta_mini %>%
  left_join(join1) %>%
  mutate(pass_QC = ifelse(is.na(ReadsPerSample), "no", "yes"))
```

save output 
```{r}
#write.csv(join2, "pinkherring_mifish_output.csv")
```



